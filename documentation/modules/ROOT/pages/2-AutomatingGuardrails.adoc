# ACCELERATE APPLICATION DEVELOPMENT LAB GUIDE
# Red Hat Summit 2023

## ABOUT THIS LAB
In this lab we'll address some ways that can help you with some major challenges we've witnessed with some of our largest customers:

* In order to meet your customer's needs, you need the ability to deliver new capabilities through secure software applications rapidly, and continuously.
* Many customers have applications that are architected and developed in such a way that they are not easily evolvable, agile enough to meet a rapid change in business reuirements, or even in a position to efficiently develop and maintain new applications, especially without reaching the same challenges again.
* IT organizations need to facilitate securely buildable and deployable applications at scale for their developers, wherever it makes sense for the business - whether on-premesis, in a cloud, or even in a hybrid combination. 

## LAB ASSETS
https://supporting.slides.link[Supporting Slides]

## INTRODUCTION
I think we can all agree that fast, secure, and continuous deployment of great software is the backbone to this generations most successful organizations. Without a great digital experience that is constantly improving, a company risks being quickly outpaced by competitors and ultimately, obsolescence.

Modern application development is an approach that enables your development team(s) to quickly respond to business needs and improve reaction to changes by rapidly updating applications and services. They are designed and packaged as microservices that are loosely coupled for easier maintenance with higher fault tolerances. Combining this with the power of a cloud-native environment, you can speed up your build and release cycles, with less operational overhead. 

People often hesitate out of intimidation of difficult technology adoptions. This demo shows the new way of application development that can change the way an organization works, increasing each technical team's agility, relieving them from the life of repeatedly putting out fires.

The lab presents a journey through the new cloud native application development, from code to production, from writing code and operating workload, to system design.

## LAB WALKTHROUGH
.Module Overview
|===
| https://link.to.module1.in.line[Enabling Immediate Productivity] |https://link.to.module2.in.line[Automating Guardrails] |https://link.to.module3.in.line[Building a Flexible Architecture]
|===

### Module Two: Automating Guardrails for Consistent Security and Operational Control
#### Lessons Learned:
How to ease the operation and management of clusters distributed across a hybrid cloud environment, while maintaining security, consistency, and operational control.

#### Instructions:

**STANDARDIZED CI/CD**

**MONITORING**

**CONFIGURATION DRIFT**




## Congratulations on completing this module!
*Please return to your user assignment or click here for https://link.to.module3.in.line[Module Three: Building a Flexible Architecture].*

*Don't forget to review the listed training courses available through Red Hat Training and Certification.*

*Additionally, below youâ€™ll find a few Red Hat Portfolio Architectures that can be useful for understanding how some of our customers are using similar technologies/concepts to what we've reviewed today. These are customer deployed solutions that Red Hat has brought in-house, boiled down into an easily understandable, consumable, and shareable format to influence innovation for our customers and partners. These solutions are available at https://redhat.com/architect/portfolio[The Red Hat Portfolio Architecture Center].*

* https://www.redhat.com/architect/portfolio/detail/4[**Cloud Native Development**] : Cloud-native development is an approach to building and running applications to fully exploit the advantages of cloud computing.
* https://www.redhat.com/architect/portfolio/detail/8[**Hybrid Multi Cloud Management with GitOps**] : Unify continuous delivery as well as secured secret management across both hybrid and multi cloud environments.
* https://www.redhat.com/architect/portfolio/detail/27[**Event Driven Automation**] : Automating event response for configuration changes, security preparedness, or emergency incident handling across a scaling estate, whether on-premises in physical data centers or in public/private clouds.





-----------------------------------------------------------------------------------------------------------
OLD CONTENT
-----------------------------------------------------------------------------------------------------------






= 2. Build CI/CD Pipelines - 30 minutes
:imagesdir: ../assets/images

== Goals of this lab

The goal of this exercise is to build and deploy the modernized customer application to OpenShift using link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/cicd/index#op-detailed-concepts[OpenShift Pipelines^]. You will accomplish this with the following steps:

* Use the https://tekton.dev/[Tekton^] Pipeline to build and deploy the new, modernized application using Red Hat JBoss Web Server instead of Apache Tomcat as the runtime.
* Set up the configuration for the *customers* service to connect to the Oracle database VM which is now running on OpenShift Container Platform
* Test the *customers* service

== 2.1. Update Oracle DBMS Connection using Helm

=== 2.1.1. Why OpenShift with Helm?

https://docs.openshift.com/container-platform/4.10/applications/working_with_helm_charts/understanding-helm.html[Helm^] is a package and install manager that standardizes and simplifies packaging and deployment of containerized applications with Kubernetes, anywhere in the hybrid cloud. Helm lets developers package their applications so that they can be easily shared and deployed by anyone in their organization and beyond.

Helm can also be used to automate *day-1* tasks like installation and basic configuration management for setting up the applications, and some *day-2* operations like performing some simple upgrades and rollbacks.

=== 2.1.2. Update the Helm Chart for a new JDBC configuration

The *customers* application in the OpenShift cluster currently has a connection failure because the application still tries to connect to the Oracle database running on RHV. To fix the issue, you need to update the *JDBC* configuration that points to the migrated Oracle database on OpenShift virtualization.

[IMPORTANT]
====
To save your time to go through the hands-on labs today, our SRE team has already migrated the VM running Oracle database to the OpenShift virtualization in the *retail-%USERID%* project.
====

The JDBC configuration is currently managed by the _Helm chart_ to automate day 1 & 2 operations for the modernized Globex retail system. Let's go back to the link:https://codeserver-codeserver-%USERID%.%SUBDOMAIN%[VS Code server^] and explore the *helm/customer-tomcat-gitops* directory.

Take a look at `persistence.properties` file to understand how the Helm chart allows you to define the JDBC configuration.

image::gitops-persistence.png[gitops-persistence]

[NOTE]
====
The best developer practice for updating the *JDBC configuration* is that you change the configurations locally in VS Code server. Then, when you commit and push the changes to your Gitea repository, it will trigger the `OpenShift pipeline and GitOps` to automatically update OpenShift `ConfigMap` and `Secret` objects.
====

Access link:https://argocd-server-retail-%USERID%.%SUBDOMAIN%[ArgoCD web console^]. Click `LOG IN VIA OPENSHIFT`:

image::argocd-login.png[argocd-login]

Then, enter your OpenShift login credentials.

* Username: `%USERID%`
* Password: `{openshift-password}`

You will see that the `customers-tomcat-gitops` status is *Degraded* because the application still refers to the old database hostname (e.g.*oracle-db-database*).

Click on `applications`.

image::argocd-application.png[argocd-application]

Click on `APP DETAILS` to show the detail page for the application. Then, switch to `PARAMETER` tab and click on `EDIT`.

image::argocd-application-details.png[argocd-application-details]

Replace keys and values of `customerDatabase` with the following data that refer to the Oracle virtual machine on Red Hat OpenShift. It should look like this:

* customerDatabase.hostname: `oracle-database`
* customerDatabase.password: `redhat`

image::argocd-application-update.png[argocd-application-update]

Click on `SAVE`, then close the popup window by clicking `X` on at the top right corner.

Now you will see the `OutOfSync` status of the `customers-tomcat-gitops` application because you just updated the application object, and it's now different from what's deployed (hence OutOfSync).

image::argocd-application-outofsync.png[argocd-application-outofsync]

Click on `SYNC`. Then, click on `SYNCHRONIZE` on the left popup window.

image::argocd-application-sync.png[argocd-application-sync]

It will take a few moments to synchronize the application. Wait for it to finish and show:

image::argocd-application-synced.png[argocd-application-synced]

CLick this link to go back to the OpenShift web console and look at the link:https://console-openshift-console.%SUBDOMAIN%/k8s/ns/retail-%USERID%/secrets/customers-secret[customers-secret^]. You will see the updated the JDBC configuration values.

image::argocd-application-secret.png[argocd-application-secret]

== 2.2. Run OpenShift Pipelines

=== 2.2.1 Why OpenShift Pipelines?

OpenShift Pipelines provides a *kubernetes-native CI/CD* framework based on https://tekton.dev[Tekton^] to design and run your pipelines, and is designed to run each step of the CI/CD pipeline in its own container, allowing each step to scale independently to meet the demands of the pipeline.

By extending Kubernetes/OpenShift with Custom Resource Definitions (CRDs), OpenShift Pipelines makes CI/CD concepts such as `pipeline`, `task`, and `step` natively in terms of increasing the scalability, security, ease of deployment capabilities of Kubernetes.

image::tekton-concept.png[tekton-concept]

The pipeline executes _tasks_ across a number of defined _steps_. There are tasks you will use that each have a single purpose:

* *Clone Repository* downloads the source code from the target Git repository.
* *Build from Source* builds the application artifact from source code. This task has been tweaked to allow selecting the target subdirectory from the repository in which the target application source is available, allowing you to have several application/components available in a single repository. *This way of versioning different services/components is highly discouraged*, as the optimal approach would be to have a dedicated repository for each component since their lifecycle should be independent. Nevertheless, this choice was made to gather all demo materials on a single repository for simplicity purposes.
* *Build Image* uses a Dockerfile packaged present in an application to build an image and push it to the target registry. The image will be tagged with the short commit hash of the source it contains.
* *Update Manifest* uses the short commit hash tag to update the application manifest in Git and point to the newly built image. Application deployment is then delegated to ArgoCD, which is continuously polling the configuration repository for changes and creates/updates all OpenShift objects accordingly.

The pipeline accepts the following parameters:

* *git-url*: URL of the target Git repository.
* *git-branch*: target branch to work with. (default: _main_)
* *app-subdir*: Subdirectory from the repository in which the application source code is stored.
* *target-namespace*: Namespace/project in which to deploy the application.
* *target-registry*: Registry to push the built image to. (default: _image-registry.openshift-image-registry.svc:5000_, i.e. the internal OpenShift container registry)

=== 2.2.2 Execute the Customers Pipelines

It is possible to configure webhooks and event listeners/triggers to automatically execute pipelines when source code commits are made.

For simplicity in this exercise, you will trigger the pipeline run manually.

First, open a new browser to access the link:https://console-openshift-console.%SUBDOMAIN%/dev-pipelines/ns/cicd-%USERID%[OpenShift Pipleline^].

Use the following credentials if you haven't logged in to the OpenShift cluster before.

image::openshift_login.png[openshift_login]

Login using your credentials:

* Username: `%USERID%`
* Password: `{openshift-password}`

Then, you will see a pre-defined `java-deployment` pipeline in the `cicd-%USERID%` project in the _Developer perspective_.

Click on the pipeline.

image::ama-pipeline.png[ama-pipeline]

Click on `Start` in *Actions* dropdown to run the pipeline.

image::ama-pipeline-start.png[ama-pipeline-start]

A *PipelineRun* represents a single run of the pipeline, tied to the source code and image resources that should be used for this specific invocation.

This dialog box is where you bind the final target values for the source repo of the _build-artifact_ step, and the target namespace to deploy in the _update-manifest-and-push_ step. Update the workspaces section using the following values, and then click *Start*.

[NOTE]
====
Leave default values for the other keys such as `git-url, git-branch, app-subdir, target-namespace, and target-registry`.
====

* ws: `customers-pvc` in *PersistentVolumeClaim*

image::ama-pipeline-start-popup.png[ama-pipeline-start-popup]

As soon as you start the *java-deployment-pipeline* pipeline, a _pipelinerun_ is instantiated and pods are created to execute the tasks that are defined in the pipeline. After a few minutes, the pipeline should finish successfully. You can hover over the steps to get a quick snapshot of the stepâ€™s progress, or click on the steps to see detailed logs of the steps.

image::ama-pipeline-complete.png[ama-pipeline-complete]

=== 2.2.3 Add Labels for better Topology View

The Globex retail system has deployed multiple microservices to the OpenShift cluster. Each microservices has complex relations with the other microservices and databases. This architecture might not be immediately understandable for developers and SREs. Fortunately the OpenShift developer console provides an intuitive `topology` view with helpful labels and annotations. These labels detail the explicit relations among deployed applications in the same namespace.

Run the following commands to add labels and annotations to each deployment to show which _languages_, _frameworks_, and _runtimes_ are used for each application:

[.console-input]
[source,bash]
----
oc project retail-%USERID% && \
oc label deployment/inventory app.kubernetes.io/part-of=inventory app.openshift.io/runtime=quarkus --overwrite && \
oc label deployment/postgresql-inventory app.kubernetes.io/part-of=inventory app.openshift.io/runtime=postgresql --overwrite && \
oc annotate deployment/inventory app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgresql-inventory"}]' --overwrite && \
oc label deployment/orders app.kubernetes.io/part-of=orders app.openshift.io/runtime=spring --overwrite && \
oc label deployment/postgresql-orders app.kubernetes.io/part-of=orders app.openshift.io/runtime=postgresql --overwrite && \
oc annotate deployment/orders app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgresql-orders"}]' --overwrite && \
oc label deployment/customers app.kubernetes.io/part-of=customers app.openshift.io/runtime=tomcat --overwrite && \
oc annotate deployment/customers app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"VirtualMachine","name":"oracle-database"}]' --overwrite && \
oc label deployment/ordersfrontend app.kubernetes.io/part-of=ordersfrontend app.openshift.io/runtime=nodejs --overwrite && \
oc annotate deployment/ordersfrontend app.openshift.io/connects-to=gateway --overwrite && \
oc label deployment/gateway app.kubernetes.io/part-of=gateway app.openshift.io/runtime=spring --overwrite && \
oc annotate deployment/gateway app.openshift.io/connects-to='["inventory","orders","customers",{"apiVersion":"apps/v1","kind":"Deployment","name":"customers"}]' --overwrite
----

[NOTE]
====
You might have no connection between `gateway` and `customers`. In that case, you can add the connection by dragging an arrow from `gateway` to `customers` _Dev Console_. This is a visual cue that the two are tied together.
====

Next, go back to the link:https://console-openshift-console.%SUBDOMAIN%/topology/ns/retail-%USERID%?view=graph[Topology View^] in `retail-%USERID%` project at Developer perspective, the applications deployment should appear as follows:

image::app-topology.png[app-topology]

== Congratulations!

You have built and deployed the modernized customer application to OpenShift using a CI/CD pipeline and connected the customer microservice to the new Oracle database running with OpenShift Virtualization.

In the next step you will first update the `gateway` to connect to the new `customers` service using dynamic discovery (vs. static IP address).

Next, you will integrate the app with OpenShift GitOps, enabling declarative description of an application's components, and automatic synchronization of the deployed application. This is critical to
improving how software is delivered, minimizing the chance for configuration drift and enabling better auditability over time. Let's go!
